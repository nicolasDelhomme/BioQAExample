#' ---
#' title: "Charlotte's Biological QA (mod'ed)"
#' author: "Nicolas Delhomme, mod'ed from Charlotte Soneson's"
#' date: "`r Sys.Date()`"
#' output:
#'  html_document:
#'    toc: true
#'    number_sections: true
#' ---
#' # Setup
#' * Temp. fix
options(connectionObserver = NULL)

#' * Libraries
suppressPackageStartupMessages({
  library(DESeq2)
  library(edgeR)
  library(ggtree)
  library(LSD)
  library(org.Hs.eg.db)
  library(RColorBrewer)
  library(SummarizedExperiment)
  library(tidyverse)
  library(treeio)
  library(tximeta)
  library(vsn)
})

#' * Graphics
pal <- brewer.pal(8,"Dark2")

#' * Data
#' Reading the metadata and modifying the content
#' 
#' dex and cell will be variables in our model. As they are
#' categorical, we change them to be factors
meta <- read.delim(here("data/airway/airway_meta.txt"), 
                   header = TRUE, as.is = TRUE)
rownames(meta) <- meta$names
meta$dex <- factor(meta$dex)
meta$cell <- factor(meta$cell)

#' A look at it
meta
#' What is a factor?
meta$dex
levels(meta$dex)
as.integer(meta$dex)

#' # Alignment vs. pseudo-alignment comparison
#' ## featureCounts
#' The following code, we do not run, it is there to show how
#' the featureCounts data was generated. `featureCounts` is a 
#' function part of the `Rsubread` library. It reads BAM files,
#' generated by a "classical" aligner and summarises the overlap
#' of the alignments with the gene annotation. _I.e._ for every gene
#' locus, it counts the number of reads that aligned there. featureCounts
#' can handle multi-mapping reads, but not in a probabilistic manner. 
#' 
#' ```{r featureCounts, echo=TRUE, eval=FALSE}
#' library(Rsubread)
#' fc <- featureCounts(files = files, 
#'                     annot.ext = gtf, 
#'                     isGTFAnnotationFile = TRUE,
#'                     GTF.featureType = "exon", 
#'                     GTF.attrType = "gene_id", 
#'                     useMetaFeatures = TRUE, 
#'                     strandSpecific = 0, 
#'                     isPairedEnd = TRUE, 
#'                     nthreads = 6)

#' Read the data generated from the command above
fc <- readRDS(here("data/airway/featureCounts/star_featureCounts.rds"))

#' let us inspect it
names(fc)
counts_featurecounts <- fc$counts
head(counts_featurecounts)
dim(counts_featurecounts)
fc$stat

#' let us visualise it
stats <- as.matrix(fc$stat %>% column_to_rownames("Status"))
barplot(stats[rowSums(stats)>0,],
        beside = TRUE,col = pal[1:3],las=2,
        cex.axis = .8,cex.names = .8,
        legend.text = rownames(stats)[rowSums(stats)>0],
        args.legend = list(horiz=TRUE,cex=.8,x="top",bty="n"))

#' ## Salmon
#' We list all quant.sf output files from Salmon
salmonfiles <- here("data/airway/salmon/", 
                      meta$names, "/quant.sf")
names(salmonfiles) <- meta$names
stopifnot(all(file.exists(salmonfiles)))

#' We extend the metadata by adding a column "files" 
#' to the metadata table. This table must contain at least
#' two columns: "names" and "files" for importing the
#' data using the `tximeta` package
coldata <- cbind(meta, files = salmonfiles, 
                 stringsAsFactors = FALSE)

#' How does it look
coldata

#' Now, we can import the quantifications
#' 
#' Remember that Salmon quantifies abundances at the transcript level
#' 
#' This function will fetch from the Gencode archive 
#' (locate at the European Bioinformatics Institue), 
#' the annotation relevant to our project, including the
#' transcript information and that of their parental gene
#' 
#' *Note*: enter 2 when prompted

st <- tximeta::tximeta(coldata)

#' let us take a look at it
st
metadata(st)
colData(st)
rowData(st)
assays(st) #plural
head(assay(st)) # the first one by default

#' However, we usually want to (start) analyse(ing) the data at 
#' the gene level
#' 
#' So we summarize the quantifications on the gene level. 
sg <- tximeta::summarizeToGene(st)

#' Did it work?
#' how many transcripts?
dim(assay(st))
#' how many genes?
dim(assay(sg))

#' And, how does it look?
head(assay(sg))

#' Looks fine, but given that we have the gene annotation
#' available, let us add gene symbols
sg <- tximeta::addIds(sg, "SYMBOL", gene = TRUE)
head(rowData(sg))

#' Because the tools (`DESeq2` and `edgeR`), 
#' we use downstream expect integers (non decimal counts),
#' we round the values. This has no impact on the analysis
counts_salmon <- round(assay(sg, "counts"))

#' ## Comparison
#' Let's compare featureCounts _vs._ Salmon for one sample
spl <- "SRR1039508"

#' for comparing, we need to make sure, both counts table are
#' sorted in the same way. We create a data.frame containing 
#' both sorted according to their gene IDs
gns <- rownames(counts_salmon)
quants <- data.frame(featureCounts = counts_featurecounts[gns, spl],
                     salmon = counts_salmon[gns, spl])

head(quants)

#' Let us plot the raw counts
heatscatter(quants$featureCounts,quants$salmon,
            xlab="featureCounts",ylab="salmon",
            main="scatterplot (raw counts)")
abline(0,1,lty=2,col="black")

#' Let us go onto a log scale
heatscatter(log10(quants$featureCounts+1),log10(quants$salmon+1),
            xlab="featureCounts",ylab="salmon",
            main="scatterplot (log10 counts + 1)")
abline(0,1,lty=2,col="black")

heatscatter(log1p(quants$featureCounts),log1p(quants$salmon),
            xlab="featureCounts",ylab="salmon",
            main="scatterplot (log counts + 1)")
abline(0,1,lty=2,col="black")

#' # Comparison after normalisation
#' 
#' We will use two commonly used tools to achieve the same:
#' 
#' `DESeq2` and `edgeR`
#' 
#' Why? Because you are likely to encounter both in the literature
#' 
#' Differences? Little - mostly taste. `DESeq2` abstracts a lot 
#' of the decisions from the user, while `edgeR` leave these all
#' to the user.
#' 
#' Let us take a look at the information we have about
#' our samples to build our model
colData(sg)

#' cell and dex are 2 variables where we have different values
#' 
#' Based on the original publication from this data, we know that 
#' they are relevant

colData(sg)$dex
colData(sg)$cell 

#' Both are factors (categorical variables),
#' but for dex, the `treatment` comes before the `control`
#' and this implies that the `treatment` would be the reference
#' we compare to. It would be easier to think the other way around,
#' so we change the order of the level
colData(sg)$dex <- relevel(colData(sg)$dex, ref = "untrt")
colData(sg)$dex

#' ## DESeq2
#' Let us create the DESeq objects
ds_se <- DESeqDataSet(sg, design = ~ cell + dex)

#' some sanity checking
stopifnot(all(colnames(counts_salmon) == rownames(meta)))

#' Here is another way to create the same object, relevant
#' if your organism is not among the ones available at
#' Gencode.
meta$dex <- relevel(meta$dex, ref = "untrt")
ds_matrix <- DESeqDataSetFromMatrix(countData = counts_salmon, 
                                    colData = meta,
                                    design = ~ cell + dex)

#' ## edgeR
#' Create the object
genetable <- data.frame(gene.id = rownames(counts_salmon),
                        stringsAsFactors = FALSE)
stopifnot(all(rownames(meta) == colnames(counts_salmon)))
dge <- DGEList(counts = counts_salmon, 
               samples = meta, 
               genes = genetable)
names(dge)

#' Here is an illustration of what I meant earlier.
#' 
#' `edgeR` leaves a lot for the user to do
#' 
#' Here we retrieve the average transcript length, use
#' it to correct the salmon expression values, before
#' calculating the library size factor (_i.e._ the difference
#' in sequencing depth between samples).
avetxlengths <- assay(sg, "length")
stopifnot(all(rownames(avetxlengths) == rownames(counts_salmon)))
stopifnot(all(colnames(avetxlengths) == colnames(counts_salmon)))
avetxlengths <- avetxlengths/exp(rowMeans(log(avetxlengths)))
offsets <- log(calcNormFactors(counts_salmon/avetxlengths)) + 
  log(colSums(counts_salmon/avetxlengths))
dge <- scaleOffset(dge, t(t(log(avetxlengths)) + offsets))
names(dge)
dge <- edgeR::calcNormFactors(dge)
dge$samples

#' Let us visualise the library size factor differences
#' 
#' It is surprisingly similar across all samples, 
#' a +/- 5% difference (we are using a toy dataset obviously)
#' 
boxplot(dge$samples$norm.factors)

#' ## Comparison
#' 
#' Neither `DESeq2` nor `edgeR` modify the count data. 
#' They calculate the parameters (such as the library size factor,
#' the dispersion, etc.) to use in their model. If we want to 
#' visualise the data in a reduced dimensionality (not 50+ thousands genes 
#' and x samples as a matrix), such as a PCA (principal component analysis),
#' or MDS (Multi-dimensional scaling), we need to normalise the data.
#' 
#' In addition to a difference in sequencing depth between samples, RNA-Seq
#' data suffers from another problem, a mean-variance relationship, _i.e._ the
#' data is heteroskedastic.
meanSdPlot(log(assay(ds_se)[rowSums(assay(ds_se))>0,]))

#' To counteract this, one can use a variance stabilising transformation
#' (VST), a heuristic that will transform the variance so it becomes 
#' independent of the mean
vsd <- DESeq2::vst(ds_se)

#' Et voila! Not perfect but good enough for visualisation
meanSdPlot(log(assay(vsd)[rowSums(assay(vsd))>0,]))

#' # Visualisation
#' Finally the **Biological QA**
#' ## DESeq2
DESeq2::plotPCA(vsd, intgroup = "cell")
DESeq2::plotPCA(vsd, intgroup = "dex")

#' ## edgeR
plotMDS(dge, top = 500, 
        labels = NULL, 
        col = as.numeric(dge$samples$dex), 
        pch = as.numeric(dge$samples$cell), 
        cex = 2, gene.selection = "common")

#' ## my own take at it
vst <- assay(vsd)
vst <- vst - min(vst)
meanSdPlot(vst[rowSums(vst)>0,])

#' ### QC on the normalised data
#' #### PCA
pc <- prcomp(t(vst))
percent <- round(summary(pc)$importance[2,]*100)

#' * Cumulative components effect
#' 
#' We define the number of variable of the model
nvar=2

#' And the number of possible combinations
nlevel=nlevels(ds_se$dex) * nlevels(ds_se$cell)

#' We plot the percentage explained by the different components, the
#' red line represent the number of variable in the model, the orange line
#' the number of variable combinations.
ggplot(tibble(x=1:length(percent),y=cumsum(percent)),aes(x=x,y=y)) +
  geom_line() + scale_y_continuous("variance explained (%)",limits=c(0,100)) +
  scale_x_continuous("Principal component") + 
  geom_vline(xintercept=nvar,colour="red",linetype="dashed",size=0.5) + 
  geom_hline(yintercept=cumsum(percent)[nvar],colour="red",linetype="dashed",size=0.5) +
  geom_vline(xintercept=nlevel,colour="orange",linetype="dashed",size=0.5) + 
  geom_hline(yintercept=cumsum(percent)[nlevel],colour="orange",linetype="dashed",size=0.5)

#' ### 2D
pc.dat <- bind_cols(PC1=pc$x[,1],
                    PC2=pc$x[,2],
                    as.data.frame(colData(ds_se)))

p <- ggplot(pc.dat,aes(x=PC1,y=PC2,col=dex,shape=cell,text=SampleName)) + 
  geom_point(size=2) + 
  ggtitle("Principal Component Analysis",subtitle="variance stabilized counts")

ggplotly(p) %>% 
  layout(xaxis=list(title=paste("PC1 (",percent[1],"%)",sep="")),
         yaxis=list(title=paste("PC2 (",percent[2],"%)",sep="")))

#' ### Sequencing depth
#' Number of genes expressed per condition at different cutoffs
conds <- ds_se$dex
dev.null <- rangeSamplesSummary(counts=vst,
                                conditions=conds,
                                nrep=3)

#' ### Heatmap
#' Filter for noise
sels <- rangeFeatureSelect(counts=vst,
                           conditions=conds,
                           nrep=3,scale=TRUE)
cutoff.pos <- 2

#' * Heatmap of "all" genes
#' 
hm <- heatmap.2(t(scale(t(vst[sels[[cutoff.pos]],]))),
                distfun=pearson.dist,
                hclustfun=function(X){hclust(X,method="ward.D2")},
                labRow = NA,trace = "none",
                labCol = conds,
                col=hpal)

plot(as.hclust(hm$colDendrogram),xlab="",sub="")

#' ### Hierarchical clustering
#' Done to assess the previous dendrogram's reproducibility
hm.pvclust <- pvclust(data = t(scale(t(vst[sels[[cutoff.pos]],]))),
                      method.hclust = "ward.D2", 
                      nboot = 1000, parallel = TRUE)

#' plot the clustering with bp and au
plot(hm.pvclust, labels = conds)
pvrect(hm.pvclust)

#' Somewhat fancier
tree2 <- full_join(as.treedata(hm.pvclust),
                   coldata %>% rename(label=names), by='label')
ggtree(tree2) + 
  geom_tippoint(aes(shape=cell)) +
  geom_tiplab(size=3,aes(label=dex),hjust=-0.5) +
  geom_nodelab(aes(label=au,color=au),hjust=-0.5,size=3) + 
  scale_color_continuous(low="red", high="blue")

#' bootstrapping results as a table
print(hm.pvclust, digits=3)


#' # Session Info
#' ```{r, session info, echo=FALSE}
#' sessionInfo()
#' ```
